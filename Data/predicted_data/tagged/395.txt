<0.6.2.93.16.41.44.garth+@NIAGARA.NECTAR.CS.CMU.EDU (Garth Gibson).0>
Type:     cmu.cs.scs
Topic:    WWC: Picturetel seminar: Patterson, Feb 10, 78:30 pm, 4623 WeH
Dates:    10Feb93
Time:     7:00  <stime>8:30 PM</stime>
PostedBy: garth+ on 6Feb93 at 16:41 from NIAGARA.NECTAR.CS.CMU.EDU (Garth Gibson)
Abstract: 

            <paragraph>West Coast Colloquium VideoConference Seminar</paragraph>

            Wed Feb 10, <location>4623 Wean Hall</location>, 7:15 pm  8:15 pm
                moderated locally by Garth Gibson

	  Observations on Massively Parallel Processors and
	     a Case for a New Theoretical Model: LogP

		      David A. Patterson,
		Computer Science Division/EECS Dept.
		 University of California, Berkeley

<paragraph>Just a few years ago I doubted that massively parallel processors (MPP) 
and software would ever converge on a common foundation, which is 
absolutely essential if MPP is to become popular. Today I can see that 
convergence, with a machine operating 1000 times faster than the
fastest Cray computer being feasible in just a few years.  Now I am 
concerned whether computer science in general (and computer 
science theory in particular) will take advantage of this opportunity
to contribute to and accelerate the success of massive parallelism. </paragraph>

<paragraph>This talk will first relay my (possibly controversial) observations:
1: We really can get to 1 TeraFLOPS(Million MFLOPS)! <sentence>And Soon! </sentence>
<sentence>2: Computer science has an obligation as well as an opportunity in MPP. </sentence>
3: MPP hardware organizations are converging, and early guesses at MPP 
	issues were wrong.
<sentence>4: Topology based models are not relevant for machines and software of the 90s. </sentence>
5: Current theoretical models (i.e., PRAM) may be too inaccurate to expect 
	them to lead to important contributions in MPP.</paragraph>

<paragraph>This is followed by an introduction to a more realistic model, called "LogP,"
developed by architects and theoreticians at Berkeley. The name LogP comes
from the four parameters of the model:</paragraph>

 L: Latency of communication in the network.
 <sentence>o: Overhead for the processor to send or receive a message from the network. </sentence>
 <sentence>g: Gap between consecutive messages sent or received at a processor. </sentence>
 <sentence>P: number of processor/memory modules. </sentence>