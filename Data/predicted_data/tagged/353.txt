<0.13.10.92.16.41.26.tmeadows@resumix.portal.com (Tim Meadows).0>
Type:     cmu.cs.robotics
Who: <speaker>Gregory D. Hager</speaker>
          Department of Computer Science
          Yale University
Topic:    Techniques for TaskDirected Sensor Data 
          Fusion and Sensor Planning
Dates:    16Oct92
Time:     3:30  <stime>5:00 PM</stime>
Place: <location>DOHERTY HALL 2315 (NOTE ROOM)</location>
PostedBy: tmeadows on 13Oct92 at 16:41 from resumix.portal.com (Tim Meadows)
Abstract: 

<paragraph>RI SEMINAR</paragraph>

 WHEN:		Friday, 16 Ocotober 1992, 3:30  <stime>5:00 pm</stime>
		Refreshments to be served by 3:15 pm

 WHERE:		DOHERTY HALL 2315 (NOTE ROOM)

 SPEAKER:		<speaker>Gregory D. Hager</speaker>  
 		Department of Computer Science
 	 	Yale University

 TITLE:		Techniques for TaskDirected Sensor Data 
 		Fusion and Sensor Planning

<paragraph>The growing popularity of flexible, highbandwidth sensing in robotic systems has posed many new problems for the control of sensors and sensor information processing.  <sentence>My approach to these problems assumes that the objective of sensing is to minimize effort while maximizing the likelihood of a good or correct decision. </sentence>  <sentence>In general, any further quantification of the latter depends heavily on the specifics of a given robot task, so I refer to this approach as ``taskdirected'' sensing. </sentence></paragraph>

<sentence>This talk describes and compares two complementary approaches to solving taskdirected sensing problems. </sentence>  <sentence>The first approach employs decisiontheoretic methods for quantifying the value of sensor information, and relies on a novel, gridbased approximation to Bayes' theorem for combining information and representing uncertainty. </sentence>  <sentence>I describe the application of these methods to a trackingbased vision system with controllable focus of attention and briefly present some experimental results. </sentence>

<sentence>The second approach employs a setbased representation of uncertainty. </sentence> <sentence>Rather than optimizing a statistical criterion, the goal of this method is to satisfy a system of inequality constraints that represent both sensor information and taskspecific decision criteria. </sentence>  <sentence>While doing so, the system adapts its data processing and data representation to the available sensor data and decision criteria. </sentence>  I show several examples, taken from the manipulation domain, where adding task constraints to the sensing probl

<paragraph>em significantly improves processing performance.  <sentence>In situations where multiple objects are present, this adaptation leads to a natural, taskdirected, focusofattention mechanism. </sentence></paragraph>

<sentence>Finally, depending on time and interest, I will briefly discuss work on generalizing setbased methods to unstructured environments, and also outline recent work in sensor planning for controlling actions. </sentence>

<paragraph>Hosted By:  Hagen Schempf,  x6884</paragraph>


                                                                  
Tim Meadows      Field Robotics Center    Carnegie Mellon Univ.   
                                                                  
<sentence>4122687085     Fax: 4126821793        tmeadows@frc.ri.cmu.edu </sentence>